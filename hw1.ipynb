{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Compute the gradient and Hessians of the loss function for linear regression with L2 regularization.\n",
    "\n",
    "We take the derivative of the loss function with respect to $w'$ and get:\n",
    "$$ \\frac{\\partial f(w')}{\\partial w'} = \\frac{1}{n} \\sum_{i=1}^{n} -y_i x_i \\frac{\\exp(-y_i w^T x_i)}{1 + \\exp(-y_i w^T x_i)} + 2\\lambda w$$\n",
    "\n",
    "Hence, the gradient is equal to:\n",
    "$$ \\nabla_{w'} f(w') = \\frac{1}{n} \\sum_{i=1}^{n} -y_i x_i \\frac{\\exp(-y_i w^T x_i)}{1 + \\exp(-y_i w^T x_i)} + 2\\lambda w$$\n",
    "\n",
    "We then take the derivative of the gradient with respect to $w'$ and get:\n",
    "$$ \\frac{\\partial^2 f(w')}{\\partial w'^2} = \\frac{\\partial \\nabla_{w'} f(w')}{\\partial w'} = \\frac{1}{n} \\sum_{i=1}^{n} x_i x_i^T \\frac{\\exp(-y_i w^T x_i)}{(1 + \\exp(-y_i w^T x_i))^2} + 2\\lambda I$$\n",
    "\n",
    "Hence, the Hessians is equal to:\n",
    "$$\\nabla^2_{w'} f(w') = \\frac{1}{n} \\sum_{i=1}^{n} x_i x_i^T \\frac{\\exp(-y_i w^T x_i)}{(1 + \\exp(-y_i w^T x_i))^2} + 2\\lambda I$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "myOmegaGrad:  tensor([[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]], grad_fn=<MmBackward0>)\n",
      "myBiasGrad:  tensor([[0.]], grad_fn=<SumBackward1>)\n"
     ]
    }
   ],
   "source": [
    "#2. Empirically verify the correctness\n",
    "import torch\n",
    "import sklearn\n",
    "from sklearn import datasets\n",
    "\n",
    "#import breast cancer dataset\n",
    "brest_cancer = datasets.load_breast_cancer()\n",
    "X = brest_cancer.data\n",
    "y = brest_cancer.target\n",
    "y = y.reshape(-1,1)\n",
    "#convert numpy array to torch tensor\n",
    "X = torch.from_numpy(X).float()\n",
    "y = torch.from_numpy(y).float()\n",
    "\n",
    "#init tensor w as a vector\n",
    "omega = torch.ones(X.shape[1],1,requires_grad=True) #w = [1...1]\n",
    "bias = torch.ones(1,1,requires_grad=True)       #w0 = 1\n",
    "\n",
    "#evaluate the gradients of f in part 1\n",
    "def f(X, y, omega, bias):\n",
    "    ll = 1\n",
    "    #compute the loss\n",
    "    loss = torch.sum(torch.log(1 + torch.exp(-y * (torch.matmul(X, omega) + bias))))*1/X.shape[0] + ll*\n",
    "    torch.sum(omega**2)^2\n",
    "    return loss\n",
    "f(X, y, omega, bias).backward()\n",
    "\n",
    "myOmegaGrad = torch.autograd.grad(f(X, y, omega, bias), omega, create_graph=True)[0]\n",
    "myBiasGrad = torch.autograd.grad(f(X, y, omega, bias), bias, create_graph=True)[0]\n",
    "print(\"myOmegaGrad: \", myOmegaGrad)\n",
    "print(\"myBiasGrad: \", myBiasGrad)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "#import all the class and download/transform the data set\n",
    "import torch\n",
    "import sklearn\n",
    "\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "# TorchVision functions for dealing with vision data sets\n",
    "from torchvision import datasets\n",
    "import torchvision.transforms as T\n",
    "\n",
    "# Matplotlib for visualization\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import ImageGrid\n",
    "\n",
    "# use a GPU if it is present\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using {device}\")\n",
    "\n",
    "## Download and load our train and test data sets, transforming them as we load for convenience\n",
    "\n",
    "training_data = datasets.FashionMNIST(\n",
    "\troot = \"data\",\n",
    "\ttrain = True,\n",
    "\tdownload = True,\n",
    "    transform = T.Compose([T.ToTensor(), T.Lambda(torch.flatten)]) # converts the images to tensors [1, 28, 28], then flatten them to vectors [1, 784]\n",
    ")\n",
    "\n",
    "testing_data = datasets.FashionMNIST(\n",
    "\troot = \"data\",\n",
    "\ttrain = False,\n",
    "\tdownload = True,\n",
    "    transform = T.Compose([T.ToTensor(), T.Lambda(torch.flatten)])\n",
    ")\n",
    "\n",
    "# Extract class 0 and class 1 since we are doing binary classification \n",
    "\n",
    "train_idx = torch.where(training_data.targets < 2)[0]\n",
    "train_subset = Subset(training_data, train_idx) # a PyTorch convenience function for extracting specific data points\n",
    "\n",
    "test_idx = torch.where(testing_data.targets < 2)[0]\n",
    "test_subset = Subset(testing_data, test_idx)\n",
    "\n",
    "## Convert these PyTorch data sets into X, y matrix vector pairs\n",
    "\n",
    "# DataLoaders are very convenient Python iterators for when we need to deal with shuffled \n",
    "# minibatches over multiple epochs, and our data can't all fit in memory at once. \n",
    "# Here we will not really use their features. We just use them to load all our training and \n",
    "# test data into the matrices\n",
    "train_dataloader = DataLoader(train_subset, batch_size=len(train_subset), shuffle=False)\n",
    "test_dataloader = DataLoader(test_subset, batch_size=len(test_subset), shuffle=False)\n",
    "\n",
    "Xtrain, ytrain= next(iter(train_dataloader))\n",
    "Xtrain = Xtrain.to(device) # send the data to the device we're using\n",
    "ytrain = ytrain.apply_(lambda c: 2*c - 1).view((len(train_subset), 1)).to(device) # convert {0,1} labels to {1,-1} labels\n",
    "\n",
    "Xtest, ytest= next(iter(test_dataloader))\n",
    "Xtest = Xtest.to(device)\n",
    "ytest = ytest.apply_(lambda c: 2*c - 1).view((len(test_subset), 1)).to(device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
